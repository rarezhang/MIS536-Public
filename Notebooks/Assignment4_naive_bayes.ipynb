{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Assignment4_naive_bayes.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timcsmith/MIS536-Public/blob/master/Notebooks/Assignment4_naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNiBvuxRO-vs"
      },
      "source": [
        "# Assignment4 - The Naive Bayes Classifier (NB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy1MBStjO-vt"
      },
      "source": [
        "# Import required packages for this chapter\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noGD-6RqO-vw"
      },
      "source": [
        "# Personal Loan Acceptance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwKmzg3sO-vw"
      },
      "source": [
        "We will be using the universalbank.csv again for this assignemnt. \n",
        "\n",
        "The file universalbank.csv contains data on 5000 customers of Universal Bank. The data include customer demographic information (age, income, etc.), the customerâ€™s relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign. In this exercise, we focus on two predictors: age, income, experience, and the outcome Personal Loan.\n",
        "\n",
        "Partition the data into training (60%) and validation (40%) sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RBN1EZ0O-vw"
      },
      "source": [
        "# Load the data into band_df dataframe bank_df\n",
        "# Only keep the columns we need: Creditcard, Online your target, Personal Loan. Drop the rest.\n",
        "\n",
        "\n",
        "# Use critical functions to explore the dataframe using print() to show results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNZB57ZmO-vy"
      },
      "source": [
        "# Does the data needs further cleaning?\n",
        "# If you think so, write your clearning process here.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98tA81JaO-v0"
      },
      "source": [
        "# Split the data into training and validation sets\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A4rBGB3O-v2"
      },
      "source": [
        "# Construct the model the perform analysis\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjNaAqKyO-v4"
      },
      "source": [
        "# Predict the classification for test dataset\n",
        "# Append your prediction, predicted probability to the testing dataset and print the new dataset out using print()\n",
        "# You should be able to view your prediction, observed outcome, and predictors for each data point side by side."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8niCTSuO-v5"
      },
      "source": [
        "# calculate the accuracy of your prediction against the observed outcome.\n",
        "\n",
        "\n",
        "# How well do you think the model does?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9tEcjJXO-v8"
      },
      "source": [
        "# Interpret your results:\n",
        "\n",
        "\n",
        "# Lesson learned from this lab:\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bffmvJYXO-v9"
      },
      "source": [
        "# Automobile Accidents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbPCdEb-O-v-"
      },
      "source": [
        "The file accidents.csv contains information on 42,183 actual automobile accidents in 2001 in the United States that involved one of three levels of injury: NO INJURY, INJURY, or FATALITY. For each accident, additional information is recorded, such as day of week, weather conditions, and road type. A firm might be interested in developing a system for quickly classifying the severity of an accident based on three predictors: weather conditions (WEATHER_R), traffic conditions (TRAF_CON_R), and road type (INT_HWY).\n",
        "\n",
        "Our goal here is to predict whether an accident just reported will involve fatality (MAX_SEV_IR = 2), a non fetal injury (MAX_SEV_IR = 1) or not injury (MAX_SEV_IR = 0).\n",
        "\n",
        "Partition the data into training (80%) and validation (20%) sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joTLVqM7O-v-"
      },
      "source": [
        "# Load the data into band_df dataframe accidents_df\n",
        "# Only keep the columns we need.Drop the rest.\n",
        "# Use critical functions to explore the dataframe using print() to show results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIaGjsPHO-wA"
      },
      "source": [
        "# Split dataset into training set and test set: 80% training and 20% validation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDhIWOanO-wB"
      },
      "source": [
        "# Construct the model the perform analysis\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUuS--xNO-wD"
      },
      "source": [
        "# Predict the classification for test dataset\n",
        "# Append your prediction, predicted probability to the testing dataset and print the new dataset out using print()\n",
        "# You should be able to view your prediction, observed outcome, and predictors for each data point side by side."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0w-iVa_O-wF"
      },
      "source": [
        "# compute model accuracy of your prediction against observed outcomes.\n",
        "\n",
        "\n",
        "# How well do you think the model does?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZl93cqEO-wG"
      },
      "source": [
        "# Optional Challenge: Can you improve the accuracy of the model to above 0.08 by finding a different set of the predictors?\n",
        "# Show you model below:\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67MR5q1_O-wI"
      },
      "source": [
        "# Interpret your results:\n",
        "\n",
        "\n",
        "# Lesson learned from this lab:\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}