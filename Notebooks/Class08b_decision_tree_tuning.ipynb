{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Class08b-decision_tree_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timcsmith/MIS536-Public/blob/master/Notebooks/Class08b_decision_tree_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxGJbLsUhuc8"
      },
      "source": [
        "# Class08 - Prediction using Decision Tree (with Hyperparameter Tuning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tuXRZKEYrDa"
      },
      "source": [
        "## Introduction and Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08EVUytY3eh"
      },
      "source": [
        "\n",
        "In this project, we reuse the [UCI's Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/census+income) census data.\n",
        "\n",
        "The first section of this exercise is a duplicate of the previous Class08-random-forest-default.ipynb. The second section demonstrates how we can use hyper parameter tuning techniques to identify the best performing parameters for the given model (in this case, Random Forests).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2A_u7rQhuc_"
      },
      "source": [
        "\n",
        "# Section 1: Prediction with Decision Tree (using default parameters)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmYLcm3aY8X5"
      },
      "source": [
        "## Step 1: Install and import necessary packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaYulo3PeZvs"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zNdljvIhuc8"
      },
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmP3fttHqieO"
      },
      "source": [
        "## Step 2: Load, clean and prepare data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGgrXNQPZT3J"
      },
      "source": [
        "### 2.1 Read data (income.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3u5LsGyhudA"
      },
      "source": [
        "income_df = pd.read_csv(\"https://raw.githubusercontent.com/timcsmith/MIS536-Public/master/Data/income.csv\", engine='python', delimiter=\", \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aOH_GFGZZFx"
      },
      "source": [
        "### 2.2 Explore the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkUM_mnHhudC",
        "outputId": "b4e542fe-5d03-4602-e4d9-06a6d0e7c65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "# Explore the dataset\n",
        "# read the first row of the dataset \n",
        "print(income_df.head())\n",
        "print(income_df.columns)\n",
        "print(income_df.describe())\n",
        "print(income_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   age         workclass  fnlwgt  ... hours-per-week  native-country income\n",
            "0   39         State-gov   77516  ...             40   United-States  <=50K\n",
            "1   50  Self-emp-not-inc   83311  ...             13   United-States  <=50K\n",
            "2   38           Private  215646  ...             40   United-States  <=50K\n",
            "3   53           Private  234721  ...             40   United-States  <=50K\n",
            "4   28           Private  338409  ...             40            Cuba  <=50K\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "                age        fnlwgt  ...  capital-loss  hours-per-week\n",
            "count  32561.000000  3.256100e+04  ...  32561.000000    32561.000000\n",
            "mean      38.581647  1.897784e+05  ...     87.303830       40.437456\n",
            "std       13.640433  1.055500e+05  ...    402.960219       12.347429\n",
            "min       17.000000  1.228500e+04  ...      0.000000        1.000000\n",
            "25%       28.000000  1.178270e+05  ...      0.000000       40.000000\n",
            "50%       37.000000  1.783560e+05  ...      0.000000       40.000000\n",
            "75%       48.000000  2.370510e+05  ...      0.000000       45.000000\n",
            "max       90.000000  1.484705e+06  ...   4356.000000       99.000000\n",
            "\n",
            "[8 rows x 6 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32561 entries, 0 to 32560\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             32561 non-null  int64 \n",
            " 1   workclass       32561 non-null  object\n",
            " 2   fnlwgt          32561 non-null  int64 \n",
            " 3   education       32561 non-null  object\n",
            " 4   education-num   32561 non-null  int64 \n",
            " 5   marital-status  32561 non-null  object\n",
            " 6   occupation      32561 non-null  object\n",
            " 7   relationship    32561 non-null  object\n",
            " 8   race            32561 non-null  object\n",
            " 9   sex             32561 non-null  object\n",
            " 10  capital-gain    32561 non-null  int64 \n",
            " 11  capital-loss    32561 non-null  int64 \n",
            " 12  hours-per-week  32561 non-null  int64 \n",
            " 13  native-country  32561 non-null  object\n",
            " 14  income          32561 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 3.7+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiaaNFX2Zf-I"
      },
      "source": [
        "### 2.3 Clean/transform data (where necessary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JuJlVGDkINJ",
        "outputId": "082781c3-db3c-44e8-a7fd-ba35f35cbbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# based on findings from data exploration, we need to clean up colum names, as there are some leading whitespace characters\n",
        "income_df.columns = [s.strip() for s in income_df.columns] \n",
        "income_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
              "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
              "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
              "       'income'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyUKMZqohudE",
        "outputId": "9f3ed92f-1ce9-40ab-a69f-e3b2e40308ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# clean the datast: sex is not numeric.\n",
        "income_df.sex = income_df.sex.replace(\"Male\", 0, regex=True)\n",
        "income_df.sex = income_df.sex.replace(\"Female\", 1, regex=True)\n",
        "income_df.sex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        1\n",
              "        ..\n",
              "32556    1\n",
              "32557    0\n",
              "32558    1\n",
              "32559    0\n",
              "32560    1\n",
              "Name: sex, Length: 32561, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7_FPefb34E3"
      },
      "source": [
        "# Transform our predictors into integers. This is necessary if we later want to test precision and recall. \n",
        "income_df.income.unique()\n",
        "income_df.income = income_df.income.replace(\"<=50K\", 0, regex=True)\n",
        "income_df.income = income_df.income.replace(\">50K\", 1, regex=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKY30W1pZxCP"
      },
      "source": [
        "## Step 3 Split data intro training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0fAfB0ThudG",
        "outputId": "47f231af-3781-4603-95b8-d9a1fca0236e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# construct datasets for analysis\n",
        "target = 'income'\n",
        "predictors = ['age', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "X = income_df[predictors]\n",
        "y = income_df[target]\n",
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       age  sex  capital-gain  capital-loss  hours-per-week\n",
            "0       39    0          2174             0              40\n",
            "1       50    0             0             0              13\n",
            "2       38    0             0             0              40\n",
            "3       53    0             0             0              40\n",
            "4       28    1             0             0              40\n",
            "...    ...  ...           ...           ...             ...\n",
            "32556   27    1             0             0              38\n",
            "32557   40    0             0             0              40\n",
            "32558   58    1             0             0              40\n",
            "32559   22    0             0             0              20\n",
            "32560   52    1         15024             0              40\n",
            "\n",
            "[32561 rows x 5 columns]\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        0\n",
            "4        0\n",
            "        ..\n",
            "32556    0\n",
            "32557    1\n",
            "32558    0\n",
            "32559    0\n",
            "32560    1\n",
            "Name: income, Length: 32561, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0DkCAoChudI",
        "outputId": "4f5824b6-d5e0-419c-c916-6be218916af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# create the training set and the test set \n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X,y, test_size=0.3, random_state=1)\n",
        "print(train_X)\n",
        "print(valid_X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       age  sex  capital-gain  capital-loss  hours-per-week\n",
            "16525   44    0             0             0              60\n",
            "14551   22    1             0             0              30\n",
            "518     21    1             0             0              35\n",
            "22524   46    0             0             0              40\n",
            "11425   17    0             0             0              20\n",
            "...    ...  ...           ...           ...             ...\n",
            "32511   25    1             0             0              40\n",
            "5192    32    0         15024             0              45\n",
            "12172   27    0             0             0              40\n",
            "235     59    0             0             0              40\n",
            "29733   33    0             0          1902              45\n",
            "\n",
            "[22792 rows x 5 columns]\n",
            "       age  sex  capital-gain  capital-loss  hours-per-week\n",
            "9646    62    1             0             0              66\n",
            "709     18    0             0             0              25\n",
            "7385    25    0         27828             0              50\n",
            "16671   33    0             0             0              40\n",
            "21932   36    1             0             0              40\n",
            "...    ...  ...           ...           ...             ...\n",
            "29663   61    0         15024             0              40\n",
            "29310   22    1             0             0              40\n",
            "29661   37    1          5013             0              40\n",
            "19491   23    0             0             0              40\n",
            "2861    44    1             0             0              40\n",
            "\n",
            "[9769 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSk0zea3qnoz"
      },
      "source": [
        "## Step 4: Create and train model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30gNRdX-qtNT"
      },
      "source": [
        "You can find details about the DecisionTree classifier [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbPfUmcEXf6K"
      },
      "source": [
        "### 4.1 Create a decision tree using all of the default parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ60Vn1AhudK"
      },
      "source": [
        "dtree=DecisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntgxBhvJXkjp"
      },
      "source": [
        "### 4.2 Fit the model to the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPL4rRlVhudM",
        "outputId": "db26a1f0-23c9-4a02-87c5-34e3dbd71ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "dtree.fit(train_X, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMvD4-9wXy_1"
      },
      "source": [
        "### 4.3 Review of the performance of the model on the validation/test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAcO31dIX7JE",
        "outputId": "797a7c84-5c1c-4ec8-c75e-12c675ea8061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "validation_predictions = dtree.predict(valid_X)\n",
        "\n",
        "print(confusion_matrix(valid_y, validation_predictions))\n",
        "print(accuracy_score(valid_y, validation_predictions))\n",
        "print(precision_score(valid_y, validation_predictions))\n",
        "print(recall_score(valid_y, validation_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7125  425]\n",
            " [1289  930]]\n",
            "0.8245470365441704\n",
            "0.6863468634686347\n",
            "0.4191077061739522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HLaMDTwaN9H"
      },
      "source": [
        "## Step 5: Deploy model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOnuFI0gaVmd"
      },
      "source": [
        "In this exercise (predicting income), there is no model deployment. Here we develop a model and test its performance on the validation data.\n",
        "\n",
        "What does \"deploying\" a model mean? Up to this point, we've trained a model to our training data and then estimated the performance of this model on new data by testing its performance on validation data.\n",
        "\n",
        "In this course, we finish after building the model. In practice, the model is used by an organization/company in some way. Using the model is often referred to as \"deploying\" the model.\n",
        "\n",
        "How a model is deployed can vary. It may simply be deployed as a notebook that reads the latest predictor data and uses the developed model to make predictions. The model can also be deployed inside enterprise decision support software that automatically makes predictions on incoming data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EouSfy5vIYm8"
      },
      "source": [
        "# Section 2: Prediction with Decision Tree (using hyperparmater tuning)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA3Yw37NeyaU"
      },
      "source": [
        "This section demonstrates how to refine the performance of a decision tree using hyperparameter tuning techniques. \n",
        "\n",
        "This section doesn't duplicate the data loading, cleaning, and splitting of the first section. This section shows how to create and test a random forest classifier using RandomSearchCV and GridSearchCV techniques. \n",
        "\n",
        "Both RandomSearchCV and GridSearchCV test different model parameters. These help to determine the parameters that produce the best performing model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqWYH75ZgZRA"
      },
      "source": [
        "## Step 1: Determine the parameters that can be \"tuned\"\n",
        "\n",
        "You can review the parameters of the model which you're trying to \"tune\". In this case, we're using a DecisionTreeClassifier. Begin by reviewing the parameters for this model found [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUIGBpt9gytG"
      },
      "source": [
        "After reviewing these parameters (while also understanding something about DecisionTrees), we can identify the following parameters that could affect model fit. \n",
        "\n",
        "* criterion\n",
        "* max_depth\n",
        "* min_samples_split\n",
        "* min_samples_leaf\n",
        "* max_leaf_nodes\n",
        "* min_impurity_decrease\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1w-3ddohW8S"
      },
      "source": [
        "### Step 2: Create an initial 'wide' range of possible hyperparameter values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAal78lyhhEx"
      },
      "source": [
        "Here we create a wide range of possible parameter values for each of the hyperparameters we've listed above. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7C9BvWWIbfg"
      },
      "source": [
        "# Criterion used to guide data splits\n",
        "criterion = ['gini', 'entropy']\n",
        "\n",
        "# Maximum number of levels in tree. If None, then nodes are expanded until all leaves are pure or until all \n",
        "# leaves contain less than min_samples_split samples.\n",
        "# default = None\n",
        "max_depth = [int(x) for x in np.linspace(5, 200, num = 40)]\n",
        "max_depth.append(None)\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "# default is 2\n",
        "min_samples_split = [1, 3, 5, 8, 10, 15]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "# default = 1 \n",
        "min_samples_leaf = [1, 2, 3, 4]\n",
        "\n",
        "# max_leaf_nodes  - Grow trees with max_leaf_nodes in best-first fashion.\n",
        "# If None then unlimited number of leaf nodes.\n",
        "# default=None \n",
        "max_leaf_nodes = [None]\n",
        "\n",
        "# min_impurity_decrease - A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
        "# default=0.0\n",
        "min_impurity_decrease = [0.000, 0.0005, 0.001, 0.005, 0.01]\n",
        "\n",
        "# Create the random grid\n",
        "param_grid_random = { 'criterion': criterion,\n",
        "                      'max_depth': max_depth,\n",
        "                      'min_samples_split': min_samples_split,\n",
        "                      'min_samples_leaf' : min_samples_leaf,\n",
        "                      'max_leaf_nodes' : max_leaf_nodes,\n",
        "                      'min_impurity_decrease' : min_impurity_decrease,\n",
        "                     }\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOlUlWyTjFt3"
      },
      "source": [
        "### Step 3: Use Randomize Search to narrow the possible range of parameter values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9-MlOV1MHyr",
        "outputId": "f5ee1e90-97d4-4a3a-9e5d-8e14bd8fc307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Use the param_grid_random for an initial \"rough\" search using Randomized search\n",
        "dtree_default = DecisionTreeClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "randomSearch = RandomizedSearchCV(estimator = dtree_default, param_distributions = param_grid_random, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "randomSearch.fit(train_X, train_y)\n",
        "bestRandomModel = randomSearch.best_estimator_\n",
        "print('Best parameters found: ', randomSearch.best_params_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:    0.6s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters found:  {'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_leaf_nodes': None, 'max_depth': 95, 'criterion': 'entropy'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    1.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGkze5JWjkAL"
      },
      "source": [
        "### Step 4: Test the performance of the selected parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baZShx5VXIr9",
        "outputId": "8ea3df06-8a7b-408f-bf46-91d9056a294d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "validation_predictions = bestRandomModel.predict(valid_X)\n",
        "print('Accuracy Score: ', accuracy_score(valid_y, validation_predictions))\n",
        "print('Precision Score: ', precision_score(valid_y, validation_predictions))\n",
        "print('Recall Score: ', recall_score(valid_y, validation_predictions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score:  0.8301770907974204\n",
            "Precision Score:  0.9388714733542319\n",
            "Recall Score:  0.2699414150518252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAqjsBT5jzw9"
      },
      "source": [
        "### Step 5: Use knowledge gained from Step 3 to create new 'narrow' range of possible hyperparameter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnKODm5APuXc"
      },
      "source": [
        "# let's take the best parameters from the the random search, and use this as a base for gridsearch\n",
        "param_grid = {\n",
        "              'min_samples_split': [1, 3, 5, 7, 9],  \n",
        "              'min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "              'min_impurity_decrease': [0.0003, 0.0005, 0.0008, 0.001, 0.002],\n",
        "              'max_leaf_nodes': [None], \n",
        "              'max_depth': [90,93,95,97,100],\n",
        "              'criterion': ['entropy'],\n",
        "              }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON2ugTU4kRFV"
      },
      "source": [
        "### Step 6: Use Grid (exhaustive) to refine model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtLzreQIQtXH",
        "outputId": "344312ca-d106-4cfe-acb8-01709ea16ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# refine our search using param_grid\n",
        "dtree_tuned = DecisionTreeClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "gridSearch = GridSearchCV(estimator = dtree_tuned, param_grid=param_grid, cv = 3, verbose=2,  n_jobs = -1)\n",
        "# Fit the random search model\n",
        "gridSearch.fit(train_X, train_y)\n",
        "bestGridModel = gridSearch.best_estimator_\n",
        "print('Best parameters found: ', gridSearch.best_params_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 625 candidates, totalling 1875 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done 490 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done 1056 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done 1796 out of 1875 | elapsed:    7.3s remaining:    0.3s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters found:  {'criterion': 'entropy', 'max_depth': 90, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0003, 'min_samples_leaf': 2, 'min_samples_split': 3}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 1875 out of 1875 | elapsed:    7.7s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAv6LTYVkhA_"
      },
      "source": [
        "### Step 7: Test the performance of the model using identified parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0fWR0cvNiec",
        "outputId": "b0f56254-61ec-4095-cd82-f6c3b4895685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "validation_predictions = bestGridModel.predict(valid_X)\n",
        "print(accuracy_score(valid_y, validation_predictions))\n",
        "print(precision_score(valid_y, validation_predictions))\n",
        "print(recall_score(valid_y, validation_predictions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8324291124987204\n",
            "0.9422492401215805\n",
            "0.2794051374493015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toa5Xyg2lzDZ"
      },
      "source": [
        "### Step 8: If necessary, repeat steps 5 through 7 with more granular and targeted parameter search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9BhtBG0lA9V"
      },
      "source": [
        "Continuing to tune your model is optional, but if there is evidence that there is room for continued improvement in the model, use the information from Step 6 to create a more refined set of parameter ranges and rerun the GridSearchCV. \n",
        "\n",
        "In this case, we increased accuracy from 0.8302 to 0.8325. The importance of this increase is context-dependent. In some contexts, every little increase is worth the effort -- in other contexts, such increases would have minimal to no benefit. In this case, we'll assume that any incremental increase in performance from repeated searching is not enough to justify continuing. \n",
        "\n",
        "NOTE: The decision to continue further is dependent on the expected incremental increase in performance, the importance of any small incremental increase (to the business), and the resources you have (time and computing power). Recognize that you generally have a \"diminishing\" returns situation, where it takes an increasingly large amount of computation (training) to gain an increasingly smaller increase in performance. "
      ]
    }
  ]
}